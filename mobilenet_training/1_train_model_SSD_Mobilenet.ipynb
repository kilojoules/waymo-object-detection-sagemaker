{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e1cd147",
   "metadata": {},
   "source": [
    "# Tensorflow Object Detection API and AWS Sagemaker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85592c17",
   "metadata": {},
   "source": [
    "In this notebook, you will train and evaluate different models using the [Tensorflow Object Detection API](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/) and [AWS Sagemaker](https://aws.amazon.com/sagemaker/). \n",
    "\n",
    "If you ever feel stuck, you can refer to this [tutorial](https://aws.amazon.com/blogs/machine-learning/training-and-deploying-models-using-tensorflow-2-with-the-object-detection-api-on-amazon-sagemaker/).\n",
    "\n",
    "## Dataset\n",
    "\n",
    "We are using the [Waymo Open Dataset](https://waymo.com/open/) for this project. The dataset has already been exported using the tfrecords format. The files have been created following the format described [here](https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/training.html#create-tensorflow-records). You can find data stored on [AWS S3](https://aws.amazon.com/s3/), AWS Object Storage. The images are saved with a resolution of 640x640."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcc1d114",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install tensorflow_io sagemaker -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96f55350",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/ec2-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sagemaker\n",
    "from sagemaker.estimator import Estimator\n",
    "from framework import CustomFramework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ccde6fd1",
   "metadata": {},
   "source": [
    "Save the IAM role in a variable called `role`. This would be useful when training the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ab6b13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::897722704235:role/service-role/SageMaker-me\n"
     ]
    }
   ],
   "source": [
    "role = sagemaker.get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae64e29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The train and val paths below are public S3 buckets created by Udacity for this project\n",
    "inputs = {'train': 's3://cd2688-object-detection-tf2/train/', \n",
    "          'val': 's3://cd2688-object-detection-tf2/val/'} \n",
    "\n",
    "# this is my personal S3 bucket to store tensorboard logs.\n",
    "tensorboard_s3_prefix = 's3://sagemaker-us-east-1-897722704235/logs/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fc16a825",
   "metadata": {},
   "source": [
    "## Container\n",
    "\n",
    "To train the model, you will first need to build a [docker](https://www.docker.com/) container with all the dependencies required by the TF Object Detection API. The code below does the following:\n",
    "* clone the Tensorflow models repository\n",
    "* get the exporter and training scripts from the repository\n",
    "* build the docker image and push it \n",
    "* print the container name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ad5ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# We already closed this\n",
    "# git clone https://github.com/tensorflow/models.git docker/models\n",
    "\n",
    "# get model_main and exporter_main files from TF2 Object Detection GitHub repository\n",
    "cp ../1_model_training/docker/models/research/object_detection/exporter_main_v2.py source_dir \n",
    "cp ../1_model_training/docker/models/research/object_detection/model_main_tf2.py source_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2dab3f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we already built and pushed this\n",
    "#image_name = 'tf2-object-detection'\n",
    "#!sh ../1_model_training/docker/build_and_push.sh $image_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e62b3562",
   "metadata": {},
   "source": [
    "To verify that the image was correctly pushed to the [Elastic Container Registry](https://aws.amazon.com/ecr/), you can look at it in the AWS webapp. For example, below you can see that three different images have been pushed to ECR. You should only see one, called `tf2-object-detection`.\n",
    "![ECR Example](../data/example_ecr.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0310b6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897722704235.dkr.ecr.us-east-1.amazonaws.com/tf2-object-detection:20251006043017\n"
     ]
    }
   ],
   "source": [
    "# display the container name\n",
    "with open (os.path.join('../1_model_training/docker', 'ecr_image_fullname.txt'), 'r') as f:\n",
    "    container = f.readlines()[0][:-1]\n",
    "\n",
    "print(container)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13b2a754",
   "metadata": {},
   "source": [
    "## Pre-trained model from model zoo\n",
    "\n",
    "As often, we are not training from scratch and we will be using a pretrained model from the TF Object Detection model zoo. You can find pretrained checkpoints [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md). Because your time is limited for this project, we recommend to only experiment with the following models:\n",
    "* SSD MobileNet V2 FPNLite 640x640\t\n",
    "* SSD ResNet50 V1 FPN 640x640 (RetinaNet50)\t\n",
    "* Faster R-CNN ResNet50 V1 640x640\t\n",
    "* EfficientDet D1 640x640\t\n",
    "* Faster R-CNN ResNet152 V1 640x640\t\n",
    "\n",
    "In the code below, the EfficientDet D1 model is downloaded and extracted. This code should be adjusted if you were to experiment with other architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c4b1d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘source_dir/checkpoint’: File exists\n",
      "--2025-10-06 07:36:36--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 142.251.179.207, 64.233.180.207, 172.253.115.207, ...\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|142.251.179.207|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20518283 (20M) [application/x-tar]\n",
      "Saving to: ‘/tmp/ssd_mobilenet.tar.gz’\n",
      "\n",
      "     0K .......... .......... .......... .......... ..........  0% 15.5M 1s\n",
      "    50K .......... .......... .......... .......... ..........  0% 30.2M 1s\n",
      "   100K .......... .......... .......... .......... ..........  0% 31.9M 1s\n",
      "   150K .......... .......... .......... .......... ..........  0% 30.6M 1s\n",
      "   200K .......... .......... .......... .......... ..........  1% 30.7M 1s\n",
      "   250K .......... .......... .......... .......... ..........  1% 25.1M 1s\n",
      "   300K .......... .......... .......... .......... ..........  1% 32.0M 1s\n",
      "   350K .......... .......... .......... .......... ..........  1% 29.0M 1s\n",
      "   400K .......... .......... .......... .......... ..........  2% 64.0M 1s\n",
      "   450K .......... .......... .......... .......... ..........  2% 35.5M 1s\n",
      "   500K .......... .......... .......... .......... ..........  2% 33.6M 1s\n",
      "   550K .......... .......... .......... .......... ..........  2% 51.3M 1s\n",
      "   600K .......... .......... .......... .......... ..........  3% 49.0M 1s\n",
      "   650K .......... .......... .......... .......... ..........  3% 50.5M 1s\n",
      "   700K .......... .......... .......... .......... ..........  3% 47.5M 1s\n",
      "   750K .......... .......... .......... .......... ..........  3% 41.3M 1s\n",
      "   800K .......... .......... .......... .......... ..........  4% 51.5M 1s\n",
      "   850K .......... .......... .......... .......... ..........  4% 52.9M 1s\n",
      "   900K .......... .......... .......... .......... ..........  4% 49.8M 1s\n",
      "   950K .......... .......... .......... .......... ..........  4% 45.4M 1s\n",
      "  1000K .......... .......... .......... .......... ..........  5% 54.5M 1s\n",
      "  1050K .......... .......... .......... .......... ..........  5% 48.9M 1s\n",
      "  1100K .......... .......... .......... .......... ..........  5% 43.6M 0s\n",
      "  1150K .......... .......... .......... .......... ..........  5%  372M 0s\n",
      "  1200K .......... .......... .......... .......... ..........  6% 39.0M 0s\n",
      "  1250K .......... .......... .......... .......... ..........  6% 53.8M 0s\n",
      "  1300K .......... .......... .......... .......... ..........  6% 47.9M 0s\n",
      "  1350K .......... .......... .......... .......... ..........  6% 48.7M 0s\n",
      "  1400K .......... .......... .......... .......... ..........  7% 41.3M 0s\n",
      "  1450K .......... .......... .......... .......... ..........  7% 50.8M 0s\n",
      "  1500K .......... .......... .......... .......... ..........  7% 48.8M 0s\n",
      "  1550K .......... .......... .......... .......... ..........  7% 49.8M 0s\n",
      "  1600K .......... .......... .......... .......... ..........  8% 42.8M 0s\n",
      "  1650K .......... .......... .......... .......... ..........  8% 46.0M 0s\n",
      "  1700K .......... .......... .......... .......... ..........  8% 55.2M 0s\n",
      "  1750K .......... .......... .......... .......... ..........  8% 42.8M 0s\n",
      "  1800K .......... .......... .......... .......... ..........  9%  352M 0s\n",
      "  1850K .......... .......... .......... .......... ..........  9% 41.0M 0s\n",
      "  1900K .......... .......... .......... .......... ..........  9% 45.5M 0s\n",
      "  1950K .......... .......... .......... .......... ..........  9% 51.7M 0s\n",
      "  2000K .......... .......... .......... .......... .......... 10% 49.9M 0s\n",
      "  2050K .......... .......... .......... .......... .......... 10% 42.8M 0s\n",
      "  2100K .......... .......... .......... .......... .......... 10% 47.9M 0s\n",
      "  2150K .......... .......... .......... .......... .......... 10% 39.8M 0s\n",
      "  2200K .......... .......... .......... .......... .......... 11% 51.7M 0s\n",
      "  2250K .......... .......... .......... .......... .......... 11% 44.1M 0s\n",
      "  2300K .......... .......... .......... .......... .......... 11% 46.5M 0s\n",
      "  2350K .......... .......... .......... .......... .......... 11% 67.6M 0s\n",
      "  2400K .......... .......... .......... .......... .......... 12% 48.5M 0s\n",
      "  2450K .......... .......... .......... .......... .......... 12%  127M 0s\n",
      "  2500K .......... .......... .......... .......... .......... 12% 39.8M 0s\n",
      "  2550K .......... .......... .......... .......... .......... 12% 46.9M 0s\n",
      "  2600K .......... .......... .......... .......... .......... 13% 52.8M 0s\n",
      "  2650K .......... .......... .......... .......... .......... 13% 48.7M 0s\n",
      "  2700K .......... .......... .......... .......... .......... 13% 42.9M 0s\n",
      "  2750K .......... .......... .......... .......... .......... 13% 48.9M 0s\n",
      "  2800K .......... .......... .......... .......... .......... 14% 46.6M 0s\n",
      "  2850K .......... .......... .......... .......... .......... 14% 47.6M 0s\n",
      "  2900K .......... .......... .......... .......... .......... 14% 42.0M 0s\n",
      "  2950K .......... .......... .......... .......... .......... 14% 34.9M 0s\n",
      "  3000K .......... .......... .......... .......... .......... 15% 78.8M 0s\n",
      "  3050K .......... .......... .......... .......... .......... 15% 67.8M 0s\n",
      "  3100K .......... .......... .......... .......... .......... 15%  111M 0s\n",
      "  3150K .......... .......... .......... .......... .......... 15% 39.9M 0s\n",
      "  3200K .......... .......... .......... .......... .......... 16% 52.3M 0s\n",
      "  3250K .......... .......... .......... .......... .......... 16% 49.3M 0s\n",
      "  3300K .......... .......... .......... .......... .......... 16% 37.8M 0s\n",
      "  3350K .......... .......... .......... .......... .......... 16% 46.0M 0s\n",
      "  3400K .......... .......... .......... .......... .......... 17% 46.3M 0s\n",
      "  3450K .......... .......... .......... .......... .......... 17% 61.5M 0s\n",
      "  3500K .......... .......... .......... .......... .......... 17%  141M 0s\n",
      "  3550K .......... .......... .......... .......... .......... 17% 41.7M 0s\n",
      "  3600K .......... .......... .......... .......... .......... 18% 45.9M 0s\n",
      "  3650K .......... .......... .......... .......... .......... 18% 42.2M 0s\n",
      "  3700K .......... .......... .......... .......... .......... 18% 49.1M 0s\n",
      "  3750K .......... .......... .......... .......... .......... 18% 42.4M 0s\n",
      "  3800K .......... .......... .......... .......... .......... 19%  310M 0s\n",
      "  3850K .......... .......... .......... .......... .......... 19% 46.1M 0s\n",
      "  3900K .......... .......... .......... .......... .......... 19% 43.7M 0s\n",
      "  3950K .......... .......... .......... .......... .......... 19% 47.9M 0s\n",
      "  4000K .......... .......... .......... .......... .......... 20% 42.2M 0s\n",
      "  4050K .......... .......... .......... .......... .......... 20% 47.2M 0s\n",
      "  4100K .......... .......... .......... .......... .......... 20%  269M 0s\n",
      "  4150K .......... .......... .......... .......... .......... 20% 45.5M 0s\n",
      "  4200K .......... .......... .......... .......... .......... 21% 47.1M 0s\n",
      "  4250K .......... .......... .......... .......... .......... 21% 41.4M 0s\n",
      "  4300K .......... .......... .......... .......... .......... 21% 47.5M 0s\n",
      "  4350K .......... .......... .......... .......... .......... 21% 42.8M 0s\n",
      "  4400K .......... .......... .......... .......... .......... 22% 63.9M 0s\n",
      "  4450K .......... .......... .......... .......... .......... 22%  124M 0s\n",
      "  4500K .......... .......... .......... .......... .......... 22% 41.5M 0s\n",
      "  4550K .......... .......... .......... .......... .......... 22% 49.6M 0s\n",
      "  4600K .......... .......... .......... .......... .......... 23% 42.3M 0s\n",
      "  4650K .......... .......... .......... .......... .......... 23% 49.0M 0s\n",
      "  4700K .......... .......... .......... .......... .......... 23% 54.2M 0s\n",
      "  4750K .......... .......... .......... .......... .......... 23%  112M 0s\n",
      "  4800K .......... .......... .......... .......... .......... 24% 46.9M 0s\n",
      "  4850K .......... .......... .......... .......... .......... 24% 41.6M 0s\n",
      "  4900K .......... .......... .......... .......... .......... 24% 51.2M 0s\n",
      "  4950K .......... .......... .......... .......... .......... 24% 43.7M 0s\n",
      "  5000K .......... .......... .......... .......... .......... 25% 35.1M 0s\n",
      "  5050K .......... .......... .......... .......... .......... 25%  328M 0s\n",
      "  5100K .......... .......... .......... .......... .......... 25% 61.2M 0s\n",
      "  5150K .......... .......... .......... .......... .......... 25% 48.7M 0s\n",
      "  5200K .......... .......... .......... .......... .......... 26% 43.2M 0s\n",
      "  5250K .......... .......... .......... .......... .......... 26% 44.8M 0s\n",
      "  5300K .......... .......... .......... .......... .......... 26% 42.6M 0s\n",
      "  5350K .......... .......... .......... .......... .......... 26% 65.4M 0s\n",
      "  5400K .......... .......... .......... .......... .......... 27%  139M 0s\n",
      "  5450K .......... .......... .......... .......... .......... 27% 40.6M 0s\n",
      "  5500K .......... .......... .......... .......... .......... 27% 47.2M 0s\n",
      "  5550K .......... .......... .......... .......... .......... 27% 42.5M 0s\n",
      "  5600K .......... .......... .......... .......... .......... 28% 48.0M 0s\n",
      "  5650K .......... .......... .......... .......... .......... 28% 57.3M 0s\n",
      "  5700K .......... .......... .......... .......... .......... 28%  117M 0s\n",
      "  5750K .......... .......... .......... .......... .......... 28% 46.2M 0s\n",
      "  5800K .......... .......... .......... .......... .......... 29% 42.7M 0s\n",
      "  5850K .......... .......... .......... .......... .......... 29% 46.1M 0s\n",
      "  5900K .......... .......... .......... .......... .......... 29% 45.2M 0s\n",
      "  5950K .......... .......... .......... .......... .......... 29% 44.1M 0s\n",
      "  6000K .......... .......... .......... .......... .......... 30%  363M 0s\n",
      "  6050K .......... .......... .......... .......... .......... 30% 41.6M 0s\n",
      "  6100K .......... .......... .......... .......... .......... 30% 53.0M 0s\n",
      "  6150K .......... .......... .......... .......... .......... 30% 17.1M 0s\n",
      "  6200K .......... .......... .......... .......... .......... 31%  350M 0s\n",
      "  6250K .......... .......... .......... .......... .......... 31%  139M 0s\n",
      "  6300K .......... .......... .......... .......... .......... 31% 62.4M 0s\n",
      "  6350K .......... .......... .......... .......... .......... 31% 50.9M 0s\n",
      "  6400K .......... .......... .......... .......... .......... 32% 79.8M 0s\n",
      "  6450K .......... .......... .......... .......... .......... 32% 43.2M 0s\n",
      "  6500K .......... .......... .......... .......... .......... 32% 44.3M 0s\n",
      "  6550K .......... .......... .......... .......... .......... 32%  301M 0s\n",
      "  6600K .......... .......... .......... .......... .......... 33% 45.1M 0s\n",
      "  6650K .......... .......... .......... .......... .......... 33% 43.2M 0s\n",
      "  6700K .......... .......... .......... .......... .......... 33% 42.2M 0s\n",
      "  6750K .......... .......... .......... .......... .......... 33% 40.5M 0s\n",
      "  6800K .......... .......... .......... .......... .......... 34%  314M 0s\n",
      "  6850K .......... .......... .......... .......... .......... 34% 47.6M 0s\n",
      "  6900K .......... .......... .......... .......... .......... 34% 43.8M 0s\n",
      "  6950K .......... .......... .......... .......... .......... 34% 43.1M 0s\n",
      "  7000K .......... .......... .......... .......... .......... 35% 44.4M 0s\n",
      "  7050K .......... .......... .......... .......... .......... 35%  255M 0s\n",
      "  7100K .......... .......... .......... .......... .......... 35% 45.1M 0s\n",
      "  7150K .......... .......... .......... .......... .......... 35% 44.9M 0s\n",
      "  7200K .......... .......... .......... .......... .......... 36% 45.2M 0s\n",
      "  7250K .......... .......... .......... .......... .......... 36% 40.7M 0s\n",
      "  7300K .......... .......... .......... .......... .......... 36%  314M 0s\n",
      "  7350K .......... .......... .......... .......... .......... 36% 44.8M 0s\n",
      "  7400K .......... .......... .......... .......... .......... 37% 45.3M 0s\n",
      "  7450K .......... .......... .......... .......... .......... 37% 45.4M 0s\n",
      "  7500K .......... .......... .......... .......... .......... 37% 55.4M 0s\n",
      "  7550K .......... .......... .......... .......... .......... 37%  161M 0s\n",
      "  7600K .......... .......... .......... .......... .......... 38% 43.7M 0s\n",
      "  7650K .......... .......... .......... .......... .......... 38% 40.4M 0s\n",
      "  7700K .......... .......... .......... .......... .......... 38% 47.3M 0s\n",
      "  7750K .......... .......... .......... .......... .......... 38% 56.1M 0s\n",
      "  7800K .......... .......... .......... .......... .......... 39%  109M 0s\n",
      "  7850K .......... .......... .......... .......... .......... 39% 46.0M 0s\n",
      "  7900K .......... .......... .......... .......... .......... 39% 40.0M 0s\n",
      "  7950K .......... .......... .......... .......... .......... 39% 49.0M 0s\n",
      "  8000K .......... .......... .......... .......... .......... 40% 44.6M 0s\n",
      "  8050K .......... .......... .......... .......... .......... 40%  223M 0s\n",
      "  8100K .......... .......... .......... .......... .......... 40% 46.4M 0s\n",
      "  8150K .......... .......... .......... .......... .......... 40% 44.4M 0s\n",
      "  8200K .......... .......... .......... .......... .......... 41% 44.0M 0s\n",
      "  8250K .......... .......... .......... .......... .......... 41% 60.8M 0s\n",
      "  8300K .......... .......... .......... .......... .......... 41%  108M 0s\n",
      "  8350K .......... .......... .......... .......... .......... 41% 46.3M 0s\n",
      "  8400K .......... .......... .......... .......... .......... 42% 41.2M 0s\n",
      "  8450K .......... .......... .......... .......... .......... 42% 45.6M 0s\n",
      "  8500K .......... .......... .......... .......... .......... 42%  280M 0s\n",
      "  8550K .......... .......... .......... .......... .......... 42% 43.7M 0s\n",
      "  8600K .......... .......... .......... .......... .......... 43% 44.4M 0s\n",
      "  8650K .......... .......... .......... .......... .......... 43% 44.1M 0s\n",
      "  8700K .......... .......... .......... .......... .......... 43% 45.4M 0s\n",
      "  8750K .......... .......... .......... .......... .......... 43%  220M 0s\n",
      "  8800K .......... .......... .......... .......... .......... 44% 47.5M 0s\n",
      "  8850K .......... .......... .......... .......... .......... 44% 44.8M 0s\n",
      "  8900K .......... .......... .......... .......... .......... 44% 43.4M 0s\n",
      "  8950K .......... .......... .......... .......... .......... 44% 44.6M 0s\n",
      "  9000K .......... .......... .......... .......... .......... 45%  370M 0s\n",
      "  9050K .......... .......... .......... .......... .......... 45% 43.6M 0s\n",
      "  9100K .......... .......... .......... .......... .......... 45% 43.5M 0s\n",
      "  9150K .......... .......... .......... .......... .......... 45% 43.4M 0s\n",
      "  9200K .......... .......... .......... .......... .......... 46% 45.5M 0s\n",
      "  9250K .......... .......... .......... .......... .......... 46%  402M 0s\n",
      "  9300K .......... .......... .......... .......... .......... 46% 43.7M 0s\n",
      "  9350K .......... .......... .......... .......... .......... 46% 43.7M 0s\n",
      "  9400K .......... .......... .......... .......... .......... 47% 40.8M 0s\n",
      "  9450K .......... .......... .......... .......... .......... 47% 59.7M 0s\n",
      "  9500K .......... .......... .......... .......... .......... 47%  138M 0s\n",
      "  9550K .......... .......... .......... .......... .......... 47% 45.4M 0s\n",
      "  9600K .......... .......... .......... .......... .......... 48% 43.4M 0s\n",
      "  9650K .......... .......... .......... .......... .......... 48% 41.8M 0s\n",
      "  9700K .......... .......... .......... .......... .......... 48% 46.2M 0s\n",
      "  9750K .......... .......... .......... .......... .......... 48%  242M 0s\n",
      "  9800K .......... .......... .......... .......... .......... 49% 46.2M 0s\n",
      "  9850K .......... .......... .......... .......... .......... 49% 43.2M 0s\n",
      "  9900K .......... .......... .......... .......... .......... 49% 45.7M 0s\n",
      "  9950K .......... .......... .......... .......... .......... 49% 43.7M 0s\n",
      " 10000K .......... .......... .......... .......... .......... 50%  399M 0s\n",
      " 10050K .......... .......... .......... .......... .......... 50% 44.3M 0s\n",
      " 10100K .......... .......... .......... .......... .......... 50% 44.5M 0s\n",
      " 10150K .......... .......... .......... .......... .......... 50% 42.9M 0s\n",
      " 10200K .......... .......... .......... .......... .......... 51% 59.0M 0s\n",
      " 10250K .......... .......... .......... .......... .......... 51%  117M 0s\n",
      " 10300K .......... .......... .......... .......... .......... 51% 45.1M 0s\n",
      " 10350K .......... .......... .......... .......... .......... 51% 43.7M 0s\n",
      " 10400K .......... .......... .......... .......... .......... 52% 37.8M 0s\n",
      " 10450K .......... .......... .......... .......... .......... 52%  366M 0s\n",
      " 10500K .......... .......... .......... .......... .......... 52% 52.7M 0s\n",
      " 10550K .......... .......... .......... .......... .......... 52% 44.4M 0s\n",
      " 10600K .......... .......... .......... .......... .......... 53% 43.0M 0s\n",
      " 10650K .......... .......... .......... .......... .......... 53% 44.4M 0s\n",
      " 10700K .......... .......... .......... .......... .......... 53%  327M 0s\n",
      " 10750K .......... .......... .......... .......... .......... 53% 43.8M 0s\n",
      " 10800K .......... .......... .......... .......... .......... 54% 44.0M 0s\n",
      " 10850K .......... .......... .......... .......... .......... 54% 44.6M 0s\n",
      " 10900K .......... .......... .......... .......... .......... 54% 38.3M 0s\n",
      " 10950K .......... .......... .......... .......... .......... 54%  344M 0s\n",
      " 11000K .......... .......... .......... .......... .......... 55% 19.7M 0s\n",
      " 11050K .......... .......... .......... .......... .......... 55%  267M 0s\n",
      " 11100K .......... .......... .......... .......... .......... 55% 93.8M 0s\n",
      " 11150K .......... .......... .......... .......... .......... 55% 45.5M 0s\n",
      " 11200K .......... .......... .......... .......... .......... 56%  313M 0s\n",
      " 11250K .......... .......... .......... .......... .......... 56% 43.9M 0s\n",
      " 11300K .......... .......... .......... .......... .......... 56% 44.0M 0s\n",
      " 11350K .......... .......... .......... .......... .......... 56% 45.1M 0s\n",
      " 11400K .......... .......... .......... .......... .......... 57% 43.1M 0s\n",
      " 11450K .......... .......... .......... .......... .......... 57%  400M 0s\n",
      " 11500K .......... .......... .......... .......... .......... 57% 43.0M 0s\n",
      " 11550K .......... .......... .......... .......... .......... 57% 44.9M 0s\n",
      " 11600K .......... .......... .......... .......... .......... 58% 44.6M 0s\n",
      " 11650K .......... .......... .......... .......... .......... 58% 43.0M 0s\n",
      " 11700K .......... .......... .......... .......... .......... 58%  295M 0s\n",
      " 11750K .......... .......... .......... .......... .......... 58% 40.9M 0s\n",
      " 11800K .......... .......... .......... .......... .......... 59% 49.8M 0s\n",
      " 11850K .......... .......... .......... .......... .......... 59% 44.7M 0s\n",
      " 11900K .......... .......... .......... .......... .......... 59% 43.3M 0s\n",
      " 11950K .......... .......... .......... .......... .......... 59%  320M 0s\n",
      " 12000K .......... .......... .......... .......... .......... 60% 45.2M 0s\n",
      " 12050K .......... .......... .......... .......... .......... 60% 42.9M 0s\n",
      " 12100K .......... .......... .......... .......... .......... 60% 44.9M 0s\n",
      " 12150K .......... .......... .......... .......... .......... 60% 57.9M 0s\n",
      " 12200K .......... .......... .......... .......... .......... 61%  113M 0s\n",
      " 12250K .......... .......... .......... .......... .......... 61% 42.3M 0s\n",
      " 12300K .......... .......... .......... .......... .......... 61% 47.3M 0s\n",
      " 12350K .......... .......... .......... .......... .......... 61% 44.1M 0s\n",
      " 12400K .......... .......... .......... .......... .......... 62%  325M 0s\n",
      " 12450K .......... .......... .......... .......... .......... 62% 44.6M 0s\n",
      " 12500K .......... .......... .......... .......... .......... 62% 45.6M 0s\n",
      " 12550K .......... .......... .......... .......... .......... 62% 41.1M 0s\n",
      " 12600K .......... .......... .......... .......... .......... 63% 44.8M 0s\n",
      " 12650K .......... .......... .......... .......... .......... 63%  377M 0s\n",
      " 12700K .......... .......... .......... .......... .......... 63% 44.0M 0s\n",
      " 12750K .......... .......... .......... .......... .......... 63% 42.1M 0s\n",
      " 12800K .......... .......... .......... .......... .......... 64% 46.4M 0s\n",
      " 12850K .......... .......... .......... .......... .......... 64% 44.1M 0s\n",
      " 12900K .......... .......... .......... .......... .......... 64%  260M 0s\n",
      " 12950K .......... .......... .......... .......... .......... 64% 45.3M 0s\n",
      " 13000K .......... .......... .......... .......... .......... 65% 42.4M 0s\n",
      " 13050K .......... .......... .......... .......... .......... 65% 45.3M 0s\n",
      " 13100K .......... .......... .......... .......... .......... 65% 45.7M 0s\n",
      " 13150K .......... .......... .......... .......... .......... 65%  231M 0s\n",
      " 13200K .......... .......... .......... .......... .......... 66% 45.6M 0s\n",
      " 13250K .......... .......... .......... .......... .......... 66% 44.5M 0s\n",
      " 13300K .......... .......... .......... .......... .......... 66% 44.3M 0s\n",
      " 13350K .......... .......... .......... .......... .......... 66% 45.1M 0s\n",
      " 13400K .......... .......... .......... .......... .......... 67%  373M 0s\n",
      " 13450K .......... .......... .......... .......... .......... 67% 44.0M 0s\n",
      " 13500K .......... .......... .......... .......... .......... 67% 44.3M 0s\n",
      " 13550K .......... .......... .......... .......... .......... 67% 42.2M 0s\n",
      " 13600K .......... .......... .......... .......... .......... 68% 45.0M 0s\n",
      " 13650K .......... .......... .......... .......... .......... 68%  315M 0s\n",
      " 13700K .......... .......... .......... .......... .......... 68% 40.2M 0s\n",
      " 13750K .......... .......... .......... .......... .......... 68% 46.4M 0s\n",
      " 13800K .......... .......... .......... .......... .......... 69% 47.6M 0s\n",
      " 13850K .......... .......... .......... .......... .......... 69% 55.9M 0s\n",
      " 13900K .......... .......... .......... .......... .......... 69%  107M 0s\n",
      " 13950K .......... .......... .......... .......... .......... 69% 45.6M 0s\n",
      " 14000K .......... .......... .......... .......... .......... 70% 44.0M 0s\n",
      " 14050K .......... .......... .......... .......... .......... 70% 44.8M 0s\n",
      " 14100K .......... .......... .......... .......... .......... 70% 43.5M 0s\n",
      " 14150K .......... .......... .......... .......... .......... 70%  292M 0s\n",
      " 14200K .......... .......... .......... .......... .......... 71% 43.8M 0s\n",
      " 14250K .......... .......... .......... .......... .......... 71% 42.2M 0s\n",
      " 14300K .......... .......... .......... .......... .......... 71% 48.9M 0s\n",
      " 14350K .......... .......... .......... .......... .......... 71% 57.7M 0s\n",
      " 14400K .......... .......... .......... .......... .......... 72% 95.9M 0s\n",
      " 14450K .......... .......... .......... .......... .......... 72% 44.8M 0s\n",
      " 14500K .......... .......... .......... .......... .......... 72% 49.3M 0s\n",
      " 14550K .......... .......... .......... .......... .......... 72% 43.9M 0s\n",
      " 14600K .......... .......... .......... .......... .......... 73%  256M 0s\n",
      " 14650K .......... .......... .......... .......... .......... 73% 46.3M 0s\n",
      " 14700K .......... .......... .......... .......... .......... 73% 40.2M 0s\n",
      " 14750K .......... .......... .......... .......... .......... 73% 32.7M 0s\n",
      " 14800K .......... .......... .......... .......... .......... 74% 76.0M 0s\n",
      " 14850K .......... .......... .......... .......... .......... 74%  265M 0s\n",
      " 14900K .......... .......... .......... .......... .......... 74% 45.7M 0s\n",
      " 14950K .......... .......... .......... .......... .......... 74% 43.5M 0s\n",
      " 15000K .......... .......... .......... .......... .......... 75% 45.9M 0s\n",
      " 15050K .......... .......... .......... .......... .......... 75% 44.1M 0s\n",
      " 15100K .......... .......... .......... .......... .......... 75%  290M 0s\n",
      " 15150K .......... .......... .......... .......... .......... 75% 17.4M 0s\n",
      " 15200K .......... .......... .......... .......... .......... 76%  246M 0s\n",
      " 15250K .......... .......... .......... .......... .......... 76%  208M 0s\n",
      " 15300K .......... .......... .......... .......... .......... 76% 68.7M 0s\n",
      " 15350K .......... .......... .......... .......... .......... 76%  305M 0s\n",
      " 15400K .......... .......... .......... .......... .......... 77% 54.0M 0s\n",
      " 15450K .......... .......... .......... .......... .......... 77% 57.7M 0s\n",
      " 15500K .......... .......... .......... .......... .......... 77% 59.0M 0s\n",
      " 15550K .......... .......... .......... .......... .......... 77% 67.9M 0s\n",
      " 15600K .......... .......... .......... .......... .......... 78%  124M 0s\n",
      " 15650K .......... .......... .......... .......... .......... 78% 61.7M 0s\n",
      " 15700K .......... .......... .......... .......... .......... 78% 78.9M 0s\n",
      " 15750K .......... .......... .......... .......... .......... 78% 63.0M 0s\n",
      " 15800K .......... .......... .......... .......... .......... 79%  102M 0s\n",
      " 15850K .......... .......... .......... .......... .......... 79%  197M 0s\n",
      " 15900K .......... .......... .......... .......... .......... 79% 88.2M 0s\n",
      " 15950K .......... .......... .......... .......... .......... 79% 85.9M 0s\n",
      " 16000K .......... .......... .......... .......... .......... 80% 66.9M 0s\n",
      " 16050K .......... .......... .......... .......... .......... 80% 94.3M 0s\n",
      " 16100K .......... .......... .......... .......... .......... 80%  286M 0s\n",
      " 16150K .......... .......... .......... .......... .......... 80% 71.0M 0s\n",
      " 16200K .......... .......... .......... .......... .......... 81% 93.6M 0s\n",
      " 16250K .......... .......... .......... .......... .......... 81%  120M 0s\n",
      " 16300K .......... .......... .......... .......... .......... 81% 99.8M 0s\n",
      " 16350K .......... .......... .......... .......... .......... 81%  244M 0s\n",
      " 16400K .......... .......... .......... .......... .......... 82% 92.5M 0s\n",
      " 16450K .......... .......... .......... .......... .......... 82%  142M 0s\n",
      " 16500K .......... .......... .......... .......... .......... 82%  107M 0s\n",
      " 16550K .......... .......... .......... .......... .......... 82%  174M 0s\n",
      " 16600K .......... .......... .......... .......... .......... 83%  148M 0s\n",
      " 16650K .......... .......... .......... .......... .......... 83%  108M 0s\n",
      " 16700K .......... .......... .......... .......... .......... 83% 70.1M 0s\n",
      " 16750K .......... .......... .......... .......... .......... 83%  195M 0s\n",
      " 16800K .......... .......... .......... .......... .......... 84%  226M 0s\n",
      " 16850K .......... .......... .......... .......... .......... 84%  145M 0s\n",
      " 16900K .......... .......... .......... .......... .......... 84%  113M 0s\n",
      " 16950K .......... .......... .......... .......... .......... 84%  130M 0s\n",
      " 17000K .......... .......... .......... .......... .......... 85%  138M 0s\n",
      " 17050K .......... .......... .......... .......... .......... 85%  363M 0s\n",
      " 17100K .......... .......... .......... .......... .......... 85%  142M 0s\n",
      " 17150K .......... .......... .......... .......... .......... 85%  109M 0s\n",
      " 17200K .......... .......... .......... .......... .......... 86%  158M 0s\n",
      " 17250K .......... .......... .......... .......... .......... 86%  164M 0s\n",
      " 17300K .......... .......... .......... .......... .......... 86%  295M 0s\n",
      " 17350K .......... .......... .......... .......... .......... 86%  197M 0s\n",
      " 17400K .......... .......... .......... .......... .......... 87%  162M 0s\n",
      " 17450K .......... .......... .......... .......... .......... 87%  131M 0s\n",
      " 17500K .......... .......... .......... .......... .......... 87%  171M 0s\n",
      " 17550K .......... .......... .......... .......... .......... 87%  286M 0s\n",
      " 17600K .......... .......... .......... .......... .......... 88%  199M 0s\n",
      " 17650K .......... .......... .......... .......... .......... 88%  153M 0s\n",
      " 17700K .......... .......... .......... .......... .......... 88%  151M 0s\n",
      " 17750K .......... .......... .......... .......... .......... 88%  188M 0s\n",
      " 17800K .......... .......... .......... .......... .......... 89%  201M 0s\n",
      " 17850K .......... .......... .......... .......... .......... 89%  173M 0s\n",
      " 17900K .......... .......... .......... .......... .......... 89%  138M 0s\n",
      " 17950K .......... .......... .......... .......... .......... 89%  133M 0s\n",
      " 18000K .......... .......... .......... .......... .......... 90%  185M 0s\n",
      " 18050K .......... .......... .......... .......... .......... 90%  212M 0s\n",
      " 18100K .......... .......... .......... .......... .......... 90%  185M 0s\n",
      " 18150K .......... .......... .......... .......... .......... 90%  130M 0s\n",
      " 18200K .......... .......... .......... .......... .......... 91%  218M 0s\n",
      " 18250K .......... .......... .......... .......... .......... 91%  204M 0s\n",
      " 18300K .......... .......... .......... .......... .......... 91%  221M 0s\n",
      " 18350K .......... .......... .......... .......... .......... 91%  146M 0s\n",
      " 18400K .......... .......... .......... .......... .......... 92%  224M 0s\n",
      " 18450K .......... .......... .......... .......... .......... 92%  236M 0s\n",
      " 18500K .......... .......... .......... .......... .......... 92%  227M 0s\n",
      " 18550K .......... .......... .......... .......... .......... 92%  152M 0s\n",
      " 18600K .......... .......... .......... .......... .......... 93%  214M 0s\n",
      " 18650K .......... .......... .......... .......... .......... 93%  163M 0s\n",
      " 18700K .......... .......... .......... .......... .......... 93%  145M 0s\n",
      " 18750K .......... .......... .......... .......... .......... 93% 98.2M 0s\n",
      " 18800K .......... .......... .......... .......... .......... 94%  139M 0s\n",
      " 18850K .......... .......... .......... .......... .......... 94%  114M 0s\n",
      " 18900K .......... .......... .......... .......... .......... 94%  134M 0s\n",
      " 18950K .......... .......... .......... .......... .......... 94%  114M 0s\n",
      " 19000K .......... .......... .......... .......... .......... 95%  122M 0s\n",
      " 19050K .......... .......... .......... .......... .......... 95%  122M 0s\n",
      " 19100K .......... .......... .......... .......... .......... 95%  129M 0s\n",
      " 19150K .......... .......... .......... .......... .......... 95%  164M 0s\n",
      " 19200K .......... .......... .......... .......... .......... 96%  317M 0s\n",
      " 19250K .......... .......... .......... .......... .......... 96%  325M 0s\n",
      " 19300K .......... .......... .......... .......... .......... 96%  391M 0s\n",
      " 19350K .......... .......... .......... .......... .......... 96%  297M 0s\n",
      " 19400K .......... .......... .......... .......... .......... 97%  312M 0s\n",
      " 19450K .......... .......... .......... .......... .......... 97%  344M 0s\n",
      " 19500K .......... .......... .......... .......... .......... 97%  325M 0s\n",
      " 19550K .......... .......... .......... .......... .......... 97%  302M 0s\n",
      " 19600K .......... .......... .......... .......... .......... 98%  389M 0s\n",
      " 19650K .......... .......... .......... .......... .......... 98%  276M 0s\n",
      " 19700K .......... .......... .......... .......... .......... 98%  322M 0s\n",
      " 19750K .......... .......... .......... .......... .......... 98%  316M 0s\n",
      " 19800K .......... .......... .......... .......... .......... 99%  307M 0s\n",
      " 19850K .......... .......... .......... .......... .......... 99%  321M 0s\n",
      " 19900K .......... .......... .......... .......... .......... 99%  395M 0s\n",
      " 19950K .......... .......... .......... .......... .......... 99%  285M 0s\n",
      " 20000K .......... .......... .......... .......              100%  292M=0.3s\n",
      "\n",
      "2025-10-06 07:36:36 (60.2 MB/s) - ‘/tmp/ssd_mobilenet.tar.gz’ saved [20518283/20518283]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir /tmp/checkpoint\n",
    "mkdir source_dir/checkpoint\n",
    "# wget -O /tmp/efficientdet.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d1_coco17_tpu-32.tar.gz\n",
    "# tar -zxvf /tmp/efficientdet.tar.gz --strip-components 2 --directory source_dir/checkpoint efficientdet_d1_coco17_tpu-32/checkpoint\n",
    "\n",
    "# Download and extract the SSD MobileNet V2 FPNLite 640x640 model\n",
    "wget -O /tmp/ssd_mobilenet.tar.gz http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
    "tar -zxvf /tmp/ssd_mobilenet.tar.gz --strip-components 2 --directory source_dir/checkpoint ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1e04a98",
   "metadata": {},
   "source": [
    "## Edit pipeline.config file\n",
    "\n",
    "The [`pipeline.config`](source_dir/pipeline.config) in the `source_dir` folder should be updated when you experiment with different models. The different config files are available [here](https://github.com/tensorflow/models/tree/master/research/object_detection/configs/tf2).\n",
    "\n",
    ">Note: The provided `pipeline.config` file works well with the `EfficientDet` model. You would need to modify it when working with other models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "47483545",
   "metadata": {},
   "source": [
    "## Launch Training Job\n",
    "\n",
    "Now that we have a dataset, a docker image and some pretrained model weights, we can launch the training job. To do so, we create a [Sagemaker Framework](https://sagemaker.readthedocs.io/en/stable/frameworks/index.html), where we indicate the container name, name of the config file, number of training steps etc.\n",
    "\n",
    "The `run_training.sh` script does the following:\n",
    "* train the model for `num_train_steps` \n",
    "* evaluate over the val dataset\n",
    "* export the model\n",
    "\n",
    "Different metrics will be displayed during the evaluation phase, including the mean average precision. These metrics can be used to quantify your model performances and compare over the different iterations.\n",
    "\n",
    "You can also monitor the training progress by navigating to **Training -> Training Jobs** from the Amazon Sagemaker dashboard in the Web UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c7175cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.telemetry.telemetry_logging:SageMaker Python SDK will collect telemetry to help us better understand our user's needs, diagnose issues, and deliver additional features.\n",
      "To opt out of telemetry, please disable via TelemetryOptOut parameter in SDK defaults config. For more information, refer to https://sagemaker.readthedocs.io/en/stable/overview.html#configuring-and-using-defaults-with-the-sagemaker-python-sdk.\n",
      "INFO:sagemaker:Creating training-job with name: tf2-object-detection-2025-10-06-08-03-20-898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-06 08:03:25 Starting - Starting the training job\n",
      "2025-10-06 08:03:25 Pending - Training job waiting for capacity...\n",
      "2025-10-06 08:03:50 Pending - Preparing the instances for training...\n",
      "2025-10-06 08:04:21 Downloading - Downloading input data...\n",
      "2025-10-06 08:04:36 Downloading - Downloading the training image.........\n",
      "2025-10-06 08:06:23 Training - Training image download completed. Training in progress...\u001b[34m2025-10-06 08:06:33,824 sagemaker-training-toolkit INFO     Provided path: /opt/ml/code  is empty, unzipping\u001b[0m\n",
      "\u001b[34m2025-10-06 08:06:34,625 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-10-06 08:06:34,660 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-10-06 08:06:34,695 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2025-10-06 08:06:34,708 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"train\": \"/opt/ml/input/data/train\",\n",
      "        \"val\": \"/opt/ml/input/data/val\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": null,\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"model_dir\": \"/opt/training\",\n",
      "        \"num_train_steps\": \"2000\",\n",
      "        \"pipeline_config_path\": \"pipeline.config\",\n",
      "        \"sample_1_of_n_eval_examples\": \"1\"\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"train\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        },\n",
      "        \"val\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.g5.xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": false,\n",
      "    \"job_name\": \"tf2-object-detection-2025-10-06-08-03-20-898\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-897722704235/tf2-object-detection-2025-10-06-08-03-20-898/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"run_training.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.g5.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.g5.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\",\n",
      "        \"topology\": null\n",
      "    },\n",
      "    \"topology\": null,\n",
      "    \"user_entry_point\": \"run_training.sh\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"model_dir\":\"/opt/training\",\"num_train_steps\":\"2000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"train\",\"val\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.g5.xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=run_training.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-897722704235/tf2-object-detection-2025-10-06-08-03-20-898/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"val\":\"/opt/ml/input/data/val\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.g5.xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":null,\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"model_dir\":\"/opt/training\",\"num_train_steps\":\"2000\",\"pipeline_config_path\":\"pipeline.config\",\"sample_1_of_n_eval_examples\":\"1\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"val\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":false,\"job_name\":\"tf2-object-detection-2025-10-06-08-03-20-898\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-897722704235/tf2-object-detection-2025-10-06-08-03-20-898/source/sourcedir.tar.gz\",\"module_name\":\"run_training.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.g5.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.g5.xlarge\"}],\"network_interface_name\":\"eth0\",\"topology\":null},\"topology\":null,\"user_entry_point\":\"run_training.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--model_dir\",\"/opt/training\",\"--num_train_steps\",\"2000\",\"--pipeline_config_path\",\"pipeline.config\",\"--sample_1_of_n_eval_examples\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_VAL=/opt/ml/input/data/val\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=/opt/training\u001b[0m\n",
      "\u001b[34mSM_HP_NUM_TRAIN_STEPS=2000\u001b[0m\n",
      "\u001b[34mSM_HP_PIPELINE_CONFIG_PATH=pipeline.config\u001b[0m\n",
      "\u001b[34mSM_HP_SAMPLE_1_OF_N_EVAL_EXAMPLES=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/lib/python38.zip:/usr/lib/python3.8:/usr/lib/python3.8/lib-dynload:/usr/local/lib/python3.8/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/bin/sh -c \"./run_training.sh --model_dir /opt/training --num_train_steps 2000 --pipeline_config_path pipeline.config --sample_1_of_n_eval_examples 1\"\u001b[0m\n",
      "\u001b[34m2025-10-06 08:06:34,708 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker Debugger as it is not installed.\u001b[0m\n",
      "\u001b[34m===TRAINING THE MODEL==\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\u001b[0m\n",
      "\u001b[34mI1006 08:06:41.127042 140479351494464 mirrored_strategy.py:419] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting train_steps: 2000\u001b[0m\n",
      "\u001b[34mI1006 08:06:41.404143 140479351494464 config_util.py:552] Maybe overwriting train_steps: 2000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI1006 08:06:41.404299 140479351494464 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mW1006 08:06:41.426182 140479351494464 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mrename to distribute_datasets_from_function\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI1006 08:06:41.432134 140479351494464 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI1006 08:06:41.433235 140479351494464 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/train/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mI1006 08:06:41.433316 140479351494464 dataset_builder.py:80] Number of filenames to read: 84\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW1006 08:06:41.438879 140479351494464 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW1006 08:06:41.457540 140479351494464 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW1006 08:06:46.971394 140479351494464 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34m`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\u001b[0m\n",
      "\u001b[34mW1006 08:06:49.416019 140479351494464 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34m`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW1006 08:06:50.630793 140479351494464 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI1006 08:06:59.335102 140450904442624 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1006 08:07:06.206982 140450904442624 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1006 08:07:11.344814 140479351494464 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1006 08:07:11.346963 140479351494464 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1006 08:07:11.347720 140479351494464 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1006 08:07:11.348382 140479351494464 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1006 08:07:11.351350 140479351494464 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1006 08:07:11.352080 140479351494464 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1006 08:07:11.352822 140479351494464 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1006 08:07:11.353479 140479351494464 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1006 08:07:11.356968 140479351494464 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mI1006 08:07:11.357838 140479351494464 cross_device_ops.py:617] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mW1006 08:07:12.949648 140450914932480 deprecation.py:569] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/deprecation.py:648: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse fn_output_signature instead\u001b[0m\n",
      "\u001b[34mI1006 08:07:13.959661 140450914932480 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1006 08:07:19.090441 140450914932480 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1006 08:07:23.901448 140450914932480 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1006 08:07:28.865928 140450914932480 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 100 per-step time 0.409s\u001b[0m\n",
      "\u001b[34mI1006 08:07:52.933484 140479351494464 model_lib_v2.py:705] Step 100 per-step time 0.409s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.42514485,\n",
      " 'Loss/localization_loss': 0.6440251,\n",
      " 'Loss/regularization_loss': 0.15187855,\n",
      " 'Loss/total_loss': 1.2210486,\n",
      " 'learning_rate': 0.0319994}\u001b[0m\n",
      "\u001b[34mI1006 08:07:52.933791 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.42514485,\n",
      " 'Loss/localization_loss': 0.6440251,\n",
      " 'Loss/regularization_loss': 0.15187855,\n",
      " 'Loss/total_loss': 1.2210486,\n",
      " 'learning_rate': 0.0319994}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 200 per-step time 0.116s\u001b[0m\n",
      "\u001b[34mI1006 08:08:04.512570 140479351494464 model_lib_v2.py:705] Step 200 per-step time 0.116s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.28777412,\n",
      " 'Loss/localization_loss': 0.3827227,\n",
      " 'Loss/regularization_loss': 0.1520733,\n",
      " 'Loss/total_loss': 0.8225701,\n",
      " 'learning_rate': 0.0373328}\u001b[0m\n",
      "\u001b[34mI1006 08:08:04.512796 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.28777412,\n",
      " 'Loss/localization_loss': 0.3827227,\n",
      " 'Loss/regularization_loss': 0.1520733,\n",
      " 'Loss/total_loss': 0.8225701,\n",
      " 'learning_rate': 0.0373328}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 300 per-step time 0.116s\u001b[0m\n",
      "\u001b[34mI1006 08:08:16.083143 140479351494464 model_lib_v2.py:705] Step 300 per-step time 0.116s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.39849818,\n",
      " 'Loss/localization_loss': 0.54048723,\n",
      " 'Loss/regularization_loss': 0.15219699,\n",
      " 'Loss/total_loss': 1.0911824,\n",
      " 'learning_rate': 0.0426662}\u001b[0m\n",
      "\u001b[34mI1006 08:08:16.083383 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.39849818,\n",
      " 'Loss/localization_loss': 0.54048723,\n",
      " 'Loss/regularization_loss': 0.15219699,\n",
      " 'Loss/total_loss': 1.0911824,\n",
      " 'learning_rate': 0.0426662}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 400 per-step time 0.116s\u001b[0m\n",
      "\u001b[34mI1006 08:08:27.633808 140479351494464 model_lib_v2.py:705] Step 400 per-step time 0.116s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.25744668,\n",
      " 'Loss/localization_loss': 0.45854163,\n",
      " 'Loss/regularization_loss': 0.152328,\n",
      " 'Loss/total_loss': 0.8683163,\n",
      " 'learning_rate': 0.047999598}\u001b[0m\n",
      "\u001b[34mI1006 08:08:27.634035 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.25744668,\n",
      " 'Loss/localization_loss': 0.45854163,\n",
      " 'Loss/regularization_loss': 0.152328,\n",
      " 'Loss/total_loss': 0.8683163,\n",
      " 'learning_rate': 0.047999598}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 500 per-step time 0.116s\u001b[0m\n",
      "\u001b[34mI1006 08:08:39.184714 140479351494464 model_lib_v2.py:705] Step 500 per-step time 0.116s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.44512823,\n",
      " 'Loss/localization_loss': 0.49785376,\n",
      " 'Loss/regularization_loss': 0.152541,\n",
      " 'Loss/total_loss': 1.095523,\n",
      " 'learning_rate': 0.053333}\u001b[0m\n",
      "\u001b[34mI1006 08:08:39.184956 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.44512823,\n",
      " 'Loss/localization_loss': 0.49785376,\n",
      " 'Loss/regularization_loss': 0.152541,\n",
      " 'Loss/total_loss': 1.095523,\n",
      " 'learning_rate': 0.053333}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 600 per-step time 0.116s\u001b[0m\n",
      "\u001b[34mI1006 08:08:50.781241 140479351494464 model_lib_v2.py:705] Step 600 per-step time 0.116s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.22233655,\n",
      " 'Loss/localization_loss': 0.3302502,\n",
      " 'Loss/regularization_loss': 0.15272963,\n",
      " 'Loss/total_loss': 0.70531636,\n",
      " 'learning_rate': 0.0586664}\u001b[0m\n",
      "\u001b[34mI1006 08:08:50.781475 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.22233655,\n",
      " 'Loss/localization_loss': 0.3302502,\n",
      " 'Loss/regularization_loss': 0.15272963,\n",
      " 'Loss/total_loss': 0.70531636,\n",
      " 'learning_rate': 0.0586664}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 700 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mI1006 08:09:02.326045 140479351494464 model_lib_v2.py:705] Step 700 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.36590815,\n",
      " 'Loss/localization_loss': 0.5195365,\n",
      " 'Loss/regularization_loss': 0.15285513,\n",
      " 'Loss/total_loss': 1.0382998,\n",
      " 'learning_rate': 0.0639998}\u001b[0m\n",
      "\u001b[34mI1006 08:09:02.326286 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.36590815,\n",
      " 'Loss/localization_loss': 0.5195365,\n",
      " 'Loss/regularization_loss': 0.15285513,\n",
      " 'Loss/total_loss': 1.0382998,\n",
      " 'learning_rate': 0.0639998}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 800 per-step time 0.116s\u001b[0m\n",
      "\u001b[34mI1006 08:09:13.894495 140479351494464 model_lib_v2.py:705] Step 800 per-step time 0.116s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.3349216,\n",
      " 'Loss/localization_loss': 0.3683034,\n",
      " 'Loss/regularization_loss': 0.1531712,\n",
      " 'Loss/total_loss': 0.8563962,\n",
      " 'learning_rate': 0.069333196}\u001b[0m\n",
      "\u001b[34mI1006 08:09:13.894724 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.3349216,\n",
      " 'Loss/localization_loss': 0.3683034,\n",
      " 'Loss/regularization_loss': 0.1531712,\n",
      " 'Loss/total_loss': 0.8563962,\n",
      " 'learning_rate': 0.069333196}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 900 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mI1006 08:09:25.404556 140479351494464 model_lib_v2.py:705] Step 900 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2998722,\n",
      " 'Loss/localization_loss': 0.508677,\n",
      " 'Loss/regularization_loss': 0.15340564,\n",
      " 'Loss/total_loss': 0.96195483,\n",
      " 'learning_rate': 0.074666604}\u001b[0m\n",
      "\u001b[34mI1006 08:09:25.404794 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.2998722,\n",
      " 'Loss/localization_loss': 0.508677,\n",
      " 'Loss/regularization_loss': 0.15340564,\n",
      " 'Loss/total_loss': 0.96195483,\n",
      " 'learning_rate': 0.074666604}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1000 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mI1006 08:09:36.925084 140479351494464 model_lib_v2.py:705] Step 1000 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.24236825,\n",
      " 'Loss/localization_loss': 0.26398498,\n",
      " 'Loss/regularization_loss': 0.15370274,\n",
      " 'Loss/total_loss': 0.660056,\n",
      " 'learning_rate': 0.08}\u001b[0m\n",
      "\u001b[34mI1006 08:09:36.925304 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.24236825,\n",
      " 'Loss/localization_loss': 0.26398498,\n",
      " 'Loss/regularization_loss': 0.15370274,\n",
      " 'Loss/total_loss': 0.660056,\n",
      " 'learning_rate': 0.08}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1100 per-step time 0.125s\u001b[0m\n",
      "\u001b[34mI1006 08:09:49.397245 140479351494464 model_lib_v2.py:705] Step 1100 per-step time 0.125s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2608191,\n",
      " 'Loss/localization_loss': 0.4061974,\n",
      " 'Loss/regularization_loss': 0.1545255,\n",
      " 'Loss/total_loss': 0.821542,\n",
      " 'learning_rate': 0.07999918}\u001b[0m\n",
      "\u001b[34mI1006 08:09:49.397468 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.2608191,\n",
      " 'Loss/localization_loss': 0.4061974,\n",
      " 'Loss/regularization_loss': 0.1545255,\n",
      " 'Loss/total_loss': 0.821542,\n",
      " 'learning_rate': 0.07999918}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1200 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mI1006 08:10:00.920366 140479351494464 model_lib_v2.py:705] Step 1200 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.237067,\n",
      " 'Loss/localization_loss': 0.35719988,\n",
      " 'Loss/regularization_loss': 0.15465309,\n",
      " 'Loss/total_loss': 0.74891996,\n",
      " 'learning_rate': 0.079996705}\u001b[0m\n",
      "\u001b[34mI1006 08:10:00.920600 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.237067,\n",
      " 'Loss/localization_loss': 0.35719988,\n",
      " 'Loss/regularization_loss': 0.15465309,\n",
      " 'Loss/total_loss': 0.74891996,\n",
      " 'learning_rate': 0.079996705}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1300 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mI1006 08:10:12.468781 140479351494464 model_lib_v2.py:705] Step 1300 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.31306067,\n",
      " 'Loss/localization_loss': 0.42745593,\n",
      " 'Loss/regularization_loss': 0.15474859,\n",
      " 'Loss/total_loss': 0.8952652,\n",
      " 'learning_rate': 0.0799926}\u001b[0m\n",
      "\u001b[34mI1006 08:10:12.469004 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.31306067,\n",
      " 'Loss/localization_loss': 0.42745593,\n",
      " 'Loss/regularization_loss': 0.15474859,\n",
      " 'Loss/total_loss': 0.8952652,\n",
      " 'learning_rate': 0.0799926}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1400 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mI1006 08:10:24.000133 140479351494464 model_lib_v2.py:705] Step 1400 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.30054504,\n",
      " 'Loss/localization_loss': 0.33468348,\n",
      " 'Loss/regularization_loss': 0.15495217,\n",
      " 'Loss/total_loss': 0.7901807,\n",
      " 'learning_rate': 0.07998685}\u001b[0m\n",
      "\u001b[34mI1006 08:10:24.000363 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.30054504,\n",
      " 'Loss/localization_loss': 0.33468348,\n",
      " 'Loss/regularization_loss': 0.15495217,\n",
      " 'Loss/total_loss': 0.7901807,\n",
      " 'learning_rate': 0.07998685}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1500 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mI1006 08:10:35.548744 140479351494464 model_lib_v2.py:705] Step 1500 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2255287,\n",
      " 'Loss/localization_loss': 0.28926438,\n",
      " 'Loss/regularization_loss': 0.15475203,\n",
      " 'Loss/total_loss': 0.6695451,\n",
      " 'learning_rate': 0.07997945}\u001b[0m\n",
      "\u001b[34mI1006 08:10:35.548961 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.2255287,\n",
      " 'Loss/localization_loss': 0.28926438,\n",
      " 'Loss/regularization_loss': 0.15475203,\n",
      " 'Loss/total_loss': 0.6695451,\n",
      " 'learning_rate': 0.07997945}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1600 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mI1006 08:10:47.092533 140479351494464 model_lib_v2.py:705] Step 1600 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.24745516,\n",
      " 'Loss/localization_loss': 0.32121906,\n",
      " 'Loss/regularization_loss': 0.1544499,\n",
      " 'Loss/total_loss': 0.7231241,\n",
      " 'learning_rate': 0.079970405}\u001b[0m\n",
      "\u001b[34mI1006 08:10:47.092757 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.24745516,\n",
      " 'Loss/localization_loss': 0.32121906,\n",
      " 'Loss/regularization_loss': 0.1544499,\n",
      " 'Loss/total_loss': 0.7231241,\n",
      " 'learning_rate': 0.079970405}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1700 per-step time 0.116s\u001b[0m\n",
      "\u001b[34mI1006 08:10:58.658266 140479351494464 model_lib_v2.py:705] Step 1700 per-step time 0.116s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.32579702,\n",
      " 'Loss/localization_loss': 0.39133805,\n",
      " 'Loss/regularization_loss': 0.15435302,\n",
      " 'Loss/total_loss': 0.8714881,\n",
      " 'learning_rate': 0.07995972}\u001b[0m\n",
      "\u001b[34mI1006 08:10:58.658483 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.32579702,\n",
      " 'Loss/localization_loss': 0.39133805,\n",
      " 'Loss/regularization_loss': 0.15435302,\n",
      " 'Loss/total_loss': 0.8714881,\n",
      " 'learning_rate': 0.07995972}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1800 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mI1006 08:11:10.153454 140479351494464 model_lib_v2.py:705] Step 1800 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2502644,\n",
      " 'Loss/localization_loss': 0.29033947,\n",
      " 'Loss/regularization_loss': 0.15422954,\n",
      " 'Loss/total_loss': 0.6948334,\n",
      " 'learning_rate': 0.0799474}\u001b[0m\n",
      "\u001b[34mI1006 08:11:10.153692 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.2502644,\n",
      " 'Loss/localization_loss': 0.29033947,\n",
      " 'Loss/regularization_loss': 0.15422954,\n",
      " 'Loss/total_loss': 0.6948334,\n",
      " 'learning_rate': 0.0799474}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 1900 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mI1006 08:11:21.657238 140479351494464 model_lib_v2.py:705] Step 1900 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2094073,\n",
      " 'Loss/localization_loss': 0.277809,\n",
      " 'Loss/regularization_loss': 0.15408581,\n",
      " 'Loss/total_loss': 0.6413021,\n",
      " 'learning_rate': 0.07993342}\u001b[0m\n",
      "\u001b[34mI1006 08:11:21.657458 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.2094073,\n",
      " 'Loss/localization_loss': 0.277809,\n",
      " 'Loss/regularization_loss': 0.15408581,\n",
      " 'Loss/total_loss': 0.6413021,\n",
      " 'learning_rate': 0.07993342}\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Step 2000 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mI1006 08:11:33.161670 140479351494464 model_lib_v2.py:705] Step 2000 per-step time 0.115s\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:{'Loss/classification_loss': 0.2565252,\n",
      " 'Loss/localization_loss': 0.39886275,\n",
      " 'Loss/regularization_loss': 0.15411004,\n",
      " 'Loss/total_loss': 0.80949795,\n",
      " 'learning_rate': 0.07991781}\u001b[0m\n",
      "\u001b[34mI1006 08:11:33.161896 140479351494464 model_lib_v2.py:708] {'Loss/classification_loss': 0.2565252,\n",
      " 'Loss/localization_loss': 0.39886275,\n",
      " 'Loss/regularization_loss': 0.15411004,\n",
      " 'Loss/total_loss': 0.80949795,\n",
      " 'learning_rate': 0.07991781}\u001b[0m\n",
      "\u001b[34m==EVALUATING THE MODEL==\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mW1006 08:11:39.478900 139928417208128 model_lib_v2.py:1089] Forced number of epochs for all eval validations to be 1.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mI1006 08:11:39.479063 139928417208128 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mI1006 08:11:39.479148 139928417208128 config_util.py:552] Maybe overwriting use_bfloat16: False\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mI1006 08:11:39.479223 139928417208128 config_util.py:552] Maybe overwriting eval_num_epochs: 1\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mW1006 08:11:39.479340 139928417208128 model_lib_v2.py:1106] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI1006 08:11:39.836135 139928417208128 dataset_builder.py:162] Reading unweighted datasets: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mI1006 08:11:39.837042 139928417208128 dataset_builder.py:79] Reading record datasets for input file: ['/opt/ml/input/data/val/*.tfrecord']\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mI1006 08:11:39.837121 139928417208128 dataset_builder.py:80] Number of filenames to read: 13\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mW1006 08:11:39.837199 139928417208128 dataset_builder.py:86] num_readers has been reduced to 13 to match input file shards.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:`shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mW1006 08:11:39.838864 139928417208128 dataset_builder.py:93] `shuffle` is false, but the input data stream is still slightly shuffled since `num_readers` > 1.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mW1006 08:11:39.840170 139928417208128 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mW1006 08:11:39.858329 139928417208128 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.data.Dataset.map()\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mW1006 08:11:43.293313 139928417208128 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mCreate a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW1006 08:11:44.083685 139928417208128 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mI1006 08:11:46.580446 139928417208128 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Found new checkpoint at /opt/training/ckpt-3\u001b[0m\n",
      "\u001b[34mI1006 08:11:46.581067 139928417208128 checkpoint_utils.py:177] Found new checkpoint at /opt/training/ckpt-3\u001b[0m\n",
      "\u001b[34m/usr/local/lib/python3.8/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mI1006 08:11:51.337835 139928417208128 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1006 08:12:01.611930 139928417208128 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mW1006 08:12:05.722969 139928417208128 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mUse `tf.cast` instead.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 0\u001b[0m\n",
      "\u001b[34mI1006 08:12:05.761868 139928417208128 model_lib_v2.py:966] Finished eval step 0\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:460: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mW1006 08:12:06.099481 139928417208128 deprecation.py:364] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:460: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mtf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 100\u001b[0m\n",
      "\u001b[34mI1006 08:12:12.785093 139928417208128 model_lib_v2.py:966] Finished eval step 100\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Finished eval step 200\u001b[0m\n",
      "\u001b[34mI1006 08:12:17.236259 139928417208128 model_lib_v2.py:966] Finished eval step 200\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Performing evaluation on 258 images.\u001b[0m\n",
      "\u001b[34mI1006 08:12:19.752127 139928417208128 coco_evaluation.py:293] Performing evaluation on 258 images.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mI1006 08:12:19.755646 139928417208128 coco_tools.py:116] Loading and preparing annotation results...\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:DONE (t=0.01s)\u001b[0m\n",
      "\u001b[34mI1006 08:12:19.767398 139928417208128 coco_tools.py:138] DONE (t=0.01s)\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Eval metrics at step 2000\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.247966 139928417208128 model_lib_v2.py:1015] Eval metrics at step 2000\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP: 0.087155\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.266457 139928417208128 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP: 0.087155\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.50IOU: 0.169363\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.267917 139928417208128 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.50IOU: 0.169363\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP@.75IOU: 0.081082\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.268939 139928417208128 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP@.75IOU: 0.081082\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (small): 0.027233\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.269874 139928417208128 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (small): 0.027233\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (medium): 0.313823\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.270750 139928417208128 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (medium): 0.313823\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Precision/mAP (large): 0.400851\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.271678 139928417208128 model_lib_v2.py:1018] #011+ DetectionBoxes_Precision/mAP (large): 0.400851\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@1: 0.020302\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.272567 139928417208128 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@1: 0.020302\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@10: 0.088216\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.273459 139928417208128 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@10: 0.088216\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100: 0.128715\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.274407 139928417208128 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100: 0.128715\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (small): 0.067128\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.275336 139928417208128 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (small): 0.067128\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (medium): 0.409306\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.276299 139928417208128 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (medium): 0.409306\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ DetectionBoxes_Recall/AR@100 (large): 0.437167\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.277290 139928417208128 model_lib_v2.py:1018] #011+ DetectionBoxes_Recall/AR@100 (large): 0.437167\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/localization_loss: 0.470392\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.278037 139928417208128 model_lib_v2.py:1018] #011+ Loss/localization_loss: 0.470392\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/classification_loss: 0.370696\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.278753 139928417208128 model_lib_v2.py:1018] #011+ Loss/classification_loss: 0.370696\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/regularization_loss: 0.154107\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.279464 139928417208128 model_lib_v2.py:1018] #011+ Loss/regularization_loss: 0.154107\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:#011+ Loss/total_loss: 0.995195\u001b[0m\n",
      "\u001b[34mI1006 08:12:28.280187 139928417208128 model_lib_v2.py:1018] #011+ Loss/total_loss: 0.995195\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mI1006 08:16:46.677672 139928417208128 checkpoint_utils.py:168] Waiting for new checkpoint at /opt/training\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Timed-out waiting for a checkpoint.\u001b[0m\n",
      "\u001b[34mI1006 08:16:55.692499 139928417208128 checkpoint_utils.py:231] Timed-out waiting for a checkpoint.\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mcreating index...\u001b[0m\n",
      "\u001b[34mindex created!\u001b[0m\n",
      "\u001b[34mRunning per image evaluation...\u001b[0m\n",
      "\u001b[34mEvaluate annotation type *bbox*\u001b[0m\n",
      "\u001b[34mDONE (t=8.28s).\u001b[0m\n",
      "\u001b[34mAccumulating evaluation results...\u001b[0m\n",
      "\u001b[34mDONE (t=0.17s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.169\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.081\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.314\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.401\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.020\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.129\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.067\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.409\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.437\u001b[0m\n",
      "\u001b[34m==EXPORTING THE MODEL==\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n",
      "\u001b[34mW1006 08:17:00.532809 140359604442944 deprecation.py:641] From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/impl/api.py:459: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\u001b[0m\n",
      "\u001b[34mInstructions for updating:\u001b[0m\n",
      "\u001b[34mback_prop=False is deprecated. Consider using tf.stop_gradient instead.\u001b[0m\n",
      "\u001b[34mInstead of:\u001b[0m\n",
      "\u001b[34mresults = tf.map_fn(fn, elems, back_prop=False)\u001b[0m\n",
      "\u001b[34mUse:\u001b[0m\n",
      "\u001b[34mresults = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\u001b[0m\n",
      "\u001b[34mI1006 08:17:04.072646 140359604442944 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1006 08:17:11.752744 140359604442944 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mI1006 08:17:14.809556 140359604442944 signature_serialization.py:148] Function `call_func` contains input name(s) resource with unsupported characters which will be renamed to weightsharedconvolutionalboxpredictor_predictiontower_conv2d_3_batchnorm_feature_4_fusedbatchnormv3_readvariableop_1_resource in the SavedModel.\u001b[0m\n",
      "\u001b[34mI1006 08:17:15.970306 140359604442944 api.py:460] feature_map_spatial_dims: [(80, 80), (40, 40), (20, 20), (10, 10), (5, 5)]\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fa750534250>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.042689 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fa750534250>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fa6f0541400>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.513580 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fa6f0541400>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f053ba30>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.513755 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f053ba30>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f053b850>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.513852 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f053b850>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fa75007f1f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.513937 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fa75007f1f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa7084c1550>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.514019 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa7084c1550>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f03dfb80>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.514105 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f03dfb80>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fa6f03df760>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.514197 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fa6f03df760>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f03dfd00>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.514291 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f03dfd00>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa70842a940>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.514385 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa70842a940>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fa6f03ea790>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.514471 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.convolutional.separable_conv2d.SeparableConv2D object at 0x7fa6f03ea790>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa70806f8e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.514566 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa70806f8e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa70806fcd0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.514661 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa70806fcd0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f05426a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.514767 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f05426a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f0466d30>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.514861 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f0466d30>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f04668e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.514967 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f04668e0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f0466790>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.515046 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f0466790>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f044cc70>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.515130 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f044cc70>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f044c370>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.515204 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f044c370>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f044ce50>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.515289 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f044ce50>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f044cac0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.515375 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f044cac0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa70807e040>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.515459 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa70807e040>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f041e8b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.515549 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f041e8b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f041e2b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.515632 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f041e2b0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f041e3a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.515716 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f041e3a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa708035070>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.515792 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa708035070>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f0251040>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.515882 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f0251040>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f0251520>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.515960 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f0251520>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f02517f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.516036 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f02517f0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa70846a430>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.516108 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa70846a430>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f04e7a00>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.516174 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f04e7a00>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa7080ff730>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.516274 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa7080ff730>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa7080ff7c0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.516361 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa7080ff7c0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa7080ffd90>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.516443 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa7080ffd90>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa7080ff370>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.516535 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa7080ff370>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f0590730>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.516616 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f0590730>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f0590d90>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.516705 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f0590d90>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f058e3a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.516782 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f058e3a0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f03e5fd0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.516855 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f03e5fd0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f03c3ac0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.516940 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f03c3ac0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f03c3f40>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.517092 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f03c3f40>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f03c3a60>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.517184 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f03c3a60>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f03c3880>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.517265 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f03c3880>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f03c3af0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.517404 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.core.freezable_batch_norm.FreezableBatchNorm object at 0x7fa6f03c3af0>, because it is not built.\u001b[0m\n",
      "\u001b[34mWARNING:tensorflow:Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f03c3bb0>, because it is not built.\u001b[0m\n",
      "\u001b[34mW1006 08:17:18.517534 140359604442944 save_impl.py:66] Skipping full serialization of Keras layer <keras.src.layers.core.lambda_layer.Lambda object at 0x7fa6f03c3bb0>, because it is not built.\u001b[0m\n",
      "\u001b[34mI1006 08:17:29.756003 140359604442944 save.py:274] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalClassHead_layer_call_fn while saving (showing 5 of 173). These functions will not be directly callable after loading.\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mI1006 08:17:45.912359 140359604442944 builder_impl.py:804] Assets written to: /tmp/exported/saved_model/assets\u001b[0m\n",
      "\u001b[34mI1006 08:17:52.758306 140359604442944 fingerprinting_utils.py:48] Writing fingerprint to /tmp/exported/saved_model/fingerprint.pb\u001b[0m\n",
      "\u001b[34mINFO:tensorflow:Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34mI1006 08:17:53.146519 140359604442944 config_util.py:253] Writing pipeline config file to /tmp/exported/pipeline.config\u001b[0m\n",
      "\u001b[34m2025-10-06 08:17:54,594 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2025-10-06 08:18:33 Uploading - Uploading generated training model\n",
      "2025-10-06 08:18:33 Completed - Training job completed\n",
      "Training seconds: 852\n",
      "Billable seconds: 852\n"
     ]
    }
   ],
   "source": [
    "tensorboard_output_config = sagemaker.debugger.TensorBoardOutputConfig(\n",
    "    s3_output_path=tensorboard_s3_prefix,\n",
    "    container_local_output_path='/opt/training/'\n",
    ")\n",
    "\n",
    "estimator = CustomFramework(\n",
    "    role=role,\n",
    "    image_uri=container,\n",
    "    entry_point='run_training.sh',\n",
    "    source_dir='source_dir/',\n",
    "    hyperparameters={\n",
    "        \"model_dir\": \"/opt/training\",        \n",
    "        \"pipeline_config_path\": \"pipeline.config\",\n",
    "        \"num_train_steps\": \"2000\",    \n",
    "        \"sample_1_of_n_eval_examples\": \"1\"\n",
    "    },\n",
    "    instance_count=1,\n",
    "    instance_type='ml.g5.xlarge',\n",
    "    tensorboard_output_config=tensorboard_output_config,\n",
    "    disable_profiler=True,\n",
    "    base_job_name='tf2-object-detection'\n",
    ")\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "84545881",
   "metadata": {},
   "source": [
    "You should be able to see your model training in the AWS webapp as shown below:\n",
    "![ECR Example](../data/example_trainings.png)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f9844f25",
   "metadata": {},
   "source": [
    "## Improve on the initial model\n",
    "\n",
    "Most likely, this initial experiment did not yield optimal results. However, you can make multiple changes to the `pipeline.config` file to improve this model. One obvious change consists in improving the data augmentation strategy. The [`preprocessor.proto`](https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto) file contains the different data augmentation method available in the Tf Object Detection API. Justify your choices of augmentations in the write-up.\n",
    "\n",
    "Keep in mind that the following are also available:\n",
    "* experiment with the optimizer: type of optimizer, learning rate, scheduler etc\n",
    "* experiment with the architecture. The Tf Object Detection API model zoo offers many architectures. Keep in mind that the pipeline.config file is unique for each architecture and you will have to edit it.\n",
    "* visualize results on the test frames using the `2_deploy_model` notebook available in this repository.\n",
    "\n",
    "In the cell below, write down all the different approaches you have experimented with, why you have chosen them and what you would have done if you had more time and resources. Justify your choices using the tensorboard visualizations (take screenshots and insert them in your write-up), the metrics on the evaluation set and the generated animation you have created with [this tool](../2_run_inference/2_deploy_model.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17284a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your write-up goes here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
